{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corruption analysis\n",
    "Today is possible for us to readily and constantly check information online, over the years more and more people got access to mobile devices and this medium became the main for information exchange and gathering. We can imagine how this can influency society, but we're not going to study how people are interacting or being influenced, we're going to analyze the relations between the Internet users...\n",
    "\n",
    "## About the data\n",
    "\n",
    "We used three datasets*:\n",
    "- Corruption Perception Index (CPI)\n",
    "- Number Of Internet Users (# people with internet access)\n",
    "- Number Of Journalists Killed\n",
    "\n",
    "**All the datasets were downloaded from [Gap Minder](https://www.gapminder.org)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules and data\n",
    "\n",
    "First we need to import the modules that we're going to use for wrangling the data. Also import the three datasets that's going to be cleaned before the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_internet = pd.read_csv('data/internet_users.csv')\n",
    "df_killings = pd.read_csv('data/num_of_journalists_killed.csv')\n",
    "df_cpi = pd.read_csv('data/corruption_perception_index_cpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list with the datasets for easier iteration\n",
    "dfs = [df_internet, df_killings, df_cpi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the data\n",
    "\n",
    "Let's analyze the dataframes to see if we have any data missing or need to adequate any data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (193, 29)\n",
      "       country  1990  1991  1992  1993     1994     1995     1996     1997  \\\n",
      "0  Afghanistan   NaN   NaN   NaN   NaN      NaN      NaN      NaN      NaN   \n",
      "1      Albania   NaN   NaN   NaN   NaN      NaN  0.01120  0.03220  0.04860   \n",
      "2      Algeria   NaN   NaN   NaN   NaN  0.00036  0.00177  0.00174  0.01030   \n",
      "3      Andorra   NaN   NaN   NaN   NaN      NaN      NaN  1.53000  3.05000   \n",
      "4       Angola   NaN   NaN   NaN   NaN      NaN      NaN  0.00078  0.00567   \n",
      "\n",
      "     1998  ...   2008   2009  2010  2011   2012  2013  2014   2015  2016  2017  \n",
      "0     NaN  ...   1.84   3.55   4.0   5.0   5.45   5.9   7.0   8.26  10.6   NaN  \n",
      "1  0.0650  ...  23.90  41.20  45.0  49.0  54.70  57.2  60.1  63.30  66.4   NaN  \n",
      "2  0.0202  ...  10.20  11.20  12.5  14.9  18.20  22.5  29.5  38.20  42.9   NaN  \n",
      "3  6.8900  ...  70.00  78.50  81.0  81.0  86.40  94.0  95.9  96.90  97.9   NaN  \n",
      "4  0.0185  ...   1.90   2.30   2.8   3.1   6.50   8.9  10.2  12.40  13.0   NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 29 columns):\n",
      "country    193 non-null object\n",
      "1990       19 non-null float64\n",
      "1991       30 non-null float64\n",
      "1992       42 non-null float64\n",
      "1993       54 non-null float64\n",
      "1994       74 non-null float64\n",
      "1995       118 non-null float64\n",
      "1996       155 non-null float64\n",
      "1997       168 non-null float64\n",
      "1998       175 non-null float64\n",
      "1999       181 non-null float64\n",
      "2000       183 non-null float64\n",
      "2001       185 non-null float64\n",
      "2002       185 non-null float64\n",
      "2003       180 non-null float64\n",
      "2004       183 non-null float64\n",
      "2005       184 non-null float64\n",
      "2006       183 non-null float64\n",
      "2007       190 non-null float64\n",
      "2008       189 non-null float64\n",
      "2009       188 non-null float64\n",
      "2010       188 non-null float64\n",
      "2011       191 non-null float64\n",
      "2012       188 non-null float64\n",
      "2013       190 non-null float64\n",
      "2014       190 non-null float64\n",
      "2015       190 non-null float64\n",
      "2016       190 non-null float64\n",
      "2017       71 non-null float64\n",
      "dtypes: float64(28), object(1)\n",
      "memory usage: 43.8+ KB\n",
      "None\n",
      "Dataframe Shape:  (100, 28)\n",
      "       country  1992  1993  1994  1995  1996  1997  1998  1999  2000  ...  \\\n",
      "0  Afghanistan   NaN   NaN   1.0   NaN   NaN   NaN   1.0   NaN   NaN  ...   \n",
      "1      Algeria   1.0   8.0  18.0  24.0   7.0   NaN   NaN   NaN   NaN  ...   \n",
      "2       Angola   1.0   3.0   1.0   1.0   1.0   NaN   1.0   NaN   NaN  ...   \n",
      "3    Argentina   NaN   NaN   NaN   NaN   NaN   1.0   NaN   1.0   NaN  ...   \n",
      "4   Azerbaijan   1.0   NaN   NaN   1.0   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "\n",
      "   2009  2010  2011  2012  2013  2014  2015  2016  2017  2018  \n",
      "0   2.0   2.0   2.0   NaN   NaN   3.0   NaN   4.0   4.0  13.0  \n",
      "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2   NaN   2.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4   1.0   NaN   1.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 28 columns):\n",
      "country    100 non-null object\n",
      "1992       16 non-null float64\n",
      "1993       19 non-null float64\n",
      "1994       20 non-null float64\n",
      "1995       16 non-null float64\n",
      "1996       14 non-null float64\n",
      "1997       13 non-null float64\n",
      "1998       17 non-null float64\n",
      "1999       10 non-null float64\n",
      "2000       16 non-null float64\n",
      "2001       20 non-null float64\n",
      "2002       10 non-null float64\n",
      "2003       16 non-null float64\n",
      "2004       19 non-null float64\n",
      "2005       18 non-null float64\n",
      "2006       16 non-null float64\n",
      "2007       20 non-null float64\n",
      "2008       14 non-null float64\n",
      "2009       22 non-null float64\n",
      "2010       21 non-null float64\n",
      "2011       23 non-null float64\n",
      "2012       20 non-null float64\n",
      "2013       13 non-null float64\n",
      "2014       20 non-null float64\n",
      "2015       21 non-null float64\n",
      "2016       15 non-null float64\n",
      "2017       17 non-null float64\n",
      "2018       15 non-null float64\n",
      "dtypes: float64(27), object(1)\n",
      "memory usage: 22.0+ KB\n",
      "None\n",
      "Dataframe Shape:  (177, 7)\n",
      "       country  2012  2013  2014  2015  2016  2017\n",
      "0  Afghanistan   8.0   8.0  12.0  11.0  15.0    15\n",
      "1      Albania  33.0  31.0  33.0  36.0  39.0    38\n",
      "2      Algeria  34.0  36.0  36.0  36.0  34.0    33\n",
      "3       Angola  22.0  23.0  19.0  15.0  18.0    19\n",
      "4    Argentina  35.0  34.0  34.0  32.0  36.0    39\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177 entries, 0 to 176\n",
      "Data columns (total 7 columns):\n",
      "country    177 non-null object\n",
      "2012       172 non-null float64\n",
      "2013       173 non-null float64\n",
      "2014       171 non-null float64\n",
      "2015       165 non-null float64\n",
      "2016       173 non-null float64\n",
      "2017       177 non-null int64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 9.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for d in dfs:\n",
    "    print('Dataframe Shape: ', d.shape)\n",
    "    print(d.head())\n",
    "    print(d.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing - Fill NaN and correct type\n",
    "\n",
    "We can observe in the log above that we have some missing numbers and one column with `int` data type. Let's fix that with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with 0 considering that we only have float or int values that are null\n",
    "# And fix data type, but skipping the first column\n",
    "for d in dfs:\n",
    "    d.fillna(0, inplace=True)\n",
    "    d = d[d.columns[1:]].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the datasets\n",
    "\n",
    "After assessing our data, let's drop some columns in our dataframes for mantain only the columns that match between those dataframes. We're going to remove the year of 2017 also, because some incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns in Internet_users dataframe\n",
    "dfs[0].drop(dfs[0].columns.to_series()['1990':'2011'], axis=1, inplace=True)\n",
    "dfs[0].drop('2017', axis=1, inplace=True)\n",
    "\n",
    "# Drop columns in Journalists_killed dataframe\n",
    "dfs[1].drop(dfs[1].columns.to_series()['1992':'2011'], axis=1, inplace=True)\n",
    "dfs[1].drop(['2017', '2018'], axis=1, inplace=True)\n",
    "\n",
    "# Drop columns in CPI dataframe\n",
    "dfs[2].drop('2017', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the data and create a unique dataset\n",
    "\n",
    "Now that our data is with the same number of columns and the missing data are filled we're going to combine the datasets following the [Tidy Data principles](https://cfss.uchicago.edu/notes/tidy-data/).\n",
    "\n",
    "![Tidy Data dataset](https://r4ds.had.co.nz/images/tidy-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>54.70</td>\n",
       "      <td>57.2</td>\n",
       "      <td>60.1</td>\n",
       "      <td>63.30</td>\n",
       "      <td>66.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>18.20</td>\n",
       "      <td>22.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>38.20</td>\n",
       "      <td>42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>86.40</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.9</td>\n",
       "      <td>96.90</td>\n",
       "      <td>97.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>6.50</td>\n",
       "      <td>8.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>12.40</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country   2012  2013  2014   2015  2016\n",
       "0  Afghanistan   5.45   5.9   7.0   8.26  10.6\n",
       "1      Albania  54.70  57.2  60.1  63.30  66.4\n",
       "2      Algeria  18.20  22.5  29.5  38.20  42.9\n",
       "3      Andorra  86.40  94.0  95.9  96.90  97.9\n",
       "4       Angola   6.50   8.9  10.2  12.40  13.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a copy of our dataframes' lists\n",
    "temp = dfs.copy()\n",
    "temp[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting tables\n",
    "\n",
    "We're going to pivot the year columns and create one unique column called `name` and one column for the `value`, this keep our data organized as described in the image above, with the columns as variables and our observations as rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(temp)):\n",
    "    temp[i]=temp[i].melt(id_vars='country', value_vars=temp[i].columns[1:7])\n",
    "    temp[i].rename(columns={'variable': 'year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After pivoting our column for the value needs to be renamed before merging the datasets\n",
    "temp[0].rename(columns={'value': 'internet_users'}, inplace=True)\n",
    "temp[1].rename(columns={'value': 'journalists_killed'}, inplace=True)\n",
    "temp[2].rename(columns={'value': 'cpi'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before merging our data, we need to exclude the rows for that countries that none journalist was killed\n",
    "group_killed = temp[1].groupby('country').sum()\n",
    "none_killed = group_killed[group_killed['journalists_killed'] == 0].index\n",
    "\n",
    "temp[1] = temp[1].set_index('country').drop(list(none_killed), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we simply merge the datasets in the indexes country and year\n",
    "t1 = temp[0].merge(temp[1], on=['country', 'year'], how='inner')\n",
    "t2 = t1.merge(temp[2], on=['country', 'year'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cpi</th>\n",
       "      <th>internet_users</th>\n",
       "      <th>journalists_killed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Afghanistan</th>\n",
       "      <th>2012</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cpi  internet_users  journalists_killed\n",
       "country     year                                          \n",
       "Afghanistan 2012   8.0            5.45                 0.0\n",
       "            2013   8.0            5.90                 0.0\n",
       "            2014  12.0            7.00                 3.0\n",
       "            2015  11.0            8.26                 0.0\n",
       "            2016  15.0           10.60                 4.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For complete our transformations we use pivot_table to define our new indexes\n",
    "ind = list(t2.columns[0:2])\n",
    "col = list(t2.columns[2:])\n",
    "\n",
    "t3 = t2.pivot_table(index=ind, values=col)\n",
    "t3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save new dataset\n",
    "\n",
    "Now that we finished the transformations needed we can save the new compiled and cleaned dataset to a new file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV new dataset\n",
    "t3.to_csv('data/cleaned_df_cpi-killings-internet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
